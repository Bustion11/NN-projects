{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMaU2H6VmOWsjmlki7zsjHk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bustion11/NN-projects/blob/main/PGAN/ProGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBW0JxB_2Q_Z"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from math import log2\n",
        "\n",
        "factors = [1, 1, 1, 1, 1/2, 1/4, 1/8, 1/16, 1/32]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class WSConv2d(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, gain=2):\n",
        "      super().__init__()\n",
        "      self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
        "      self.scale = (gain/(in_channels * kernel_size ** 2)) ** 0.5\n",
        "      self.bias = self.conv.bias\n",
        "      self.conv.bias = None\n",
        "\n",
        "      # initiliaze the layer\n",
        "\n",
        "      nn.init.normal_(self.conv.weight)\n",
        "      nn.init.zeros_(self.bias)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.conv(x*self.scale) + self.bias.view(1, self.bias.shape[0], 1, 1)"
      ],
      "metadata": {
        "id": "mN84NzXy8coY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PixelNorm(nn.Module):\n",
        "  def __init__(self):\n",
        "      super().__init__()\n",
        "      self.epsilon = 1e-8\n",
        "  def forward(self, x):\n",
        "    return x/torch.sqrt(torch.mean(x**2, dim=1, keepdim=True) + self.epsilon)"
      ],
      "metadata": {
        "id": "LTZrpfA08hYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, use_pixnorm=True):\n",
        "    super().__init__()\n",
        "    self.conv1 = WSConv2d(in_channels, out_channels)\n",
        "    self.conv2 = WSConv2d(out_channels, out_channels)\n",
        "    self.leaky = nn.LeakyReLU(0.2)\n",
        "    self.pn = PixelNorm()\n",
        "    self.use_pn = use_pixnorm\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.leaky(self.conv1(x))\n",
        "    x = self.pn(x) if self.use_pn else x\n",
        "\n",
        "    x = self.leaky(self.conv2(x))\n",
        "    x = self.pn(x) if self.use_pn else x\n",
        "    return x"
      ],
      "metadata": {
        "id": "Zuzk8uCm8k98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self, z_dim, in_channels, img_channels=3):\n",
        "    super().__init__()\n",
        "    self.initial = nn.Sequential(\n",
        "        PixelNorm(),\n",
        "        nn.ConvTranspose2d(z_dim, in_channels, 4, 1, 0), # 1x1 -> 4x4\n",
        "        nn.LeakyReLU(0.2),\n",
        "        WSConv2d(in_channels, in_channels, kernel_size=3, stride=1, padding=1),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        PixelNorm()\n",
        "    )\n",
        "\n",
        "    self.initial_rgb = WSConv2d(in_channels, img_channels, kernel_size=1, stride=1, padding=0)\n",
        "    self.prog_blocks, self.rgb_layers = (nn.ModuleList(), nn.ModuleList([self.initial_rgb]))\n",
        "\n",
        "    for i in range(len(factors) - 1):\n",
        "      conv_in_c = int(in_channels * factors[i])\n",
        "      conv_out_c = int(in_channels * factors[i+1])\n",
        "\n",
        "      self.prog_blocks.append(ConvBlock(conv_in_c, conv_out_c))\n",
        "      self.rgb_layers.append(WSConv2d(conv_out_c, img_channels, kernel_size=1, stride=1, padding=0))\n",
        "\n",
        "  def _fade_in(self, alpha, upscaled, generated):\n",
        "    return torch.tanh(alpha*generated + (1-alpha)*upscaled)\n",
        "  \n",
        "  def forward(self, x, alpha, steps):\n",
        "    out = self.initial(x)\n",
        "\n",
        "    if steps == 0:\n",
        "      return self.initial_rgb(out)\n",
        "    \n",
        "    for step in range(steps):\n",
        "      upscaled = F.interpolate(out, scale_factor=2, mode=\"nearest\")\n",
        "      out = self.prog_blocks[step](upscaled)\n",
        "    \n",
        "    final_upscaled = self.rgb_layers[steps-1](upscaled)\n",
        "    final_out = self.rgb_layers[steps](out)\n",
        "    return self._fade_in(alpha, final_upscaled, final_out)"
      ],
      "metadata": {
        "id": "XBGgWr4X8oHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Generator(512, 512)\n",
        "example = torch.randn(3, 512, 1, 1)\n",
        "print(example.requires_grad)\n",
        "example = model(example, 1, 4)\n",
        "print(example.shape)\n",
        "print(example.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxIZaKaVH4UK",
        "outputId": "992fb22d-13f9-439d-9b25-5e745296f47c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "torch.Size([3, 3, 64, 64])\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x-lI4SRbH0Q_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, z_dim, in_channels, img_channels=3):\n",
        "    super().__init__()\n",
        "    self.prog_blocks, self.rgb_layers = nn.ModuleList(), nn.ModuleList()\n",
        "    self.leaky = nn.LeakyReLU(0.2)\n",
        "\n",
        "    for i in range(len(factors)-1, 0, -1):\n",
        "      conv_in_c = int(in_channels*factors[i])\n",
        "      conv_out_c = int(in_channels*factors[i-1])\n",
        "      self.prog_blocks.append(ConvBlock(conv_in_c, conv_out_c, use_pixnorm=False))\n",
        "      self.rgb_layers.append(WSConv2d(img_channels, conv_in_c, kernel_size=1, stride=1, padding=0))\n",
        "\n",
        "    self.initial_rgb = WSConv2d(img_channels, in_channels, kernel_size=1, stride=1, padding=0)\n",
        "    self.rgb_layers.append(self.initial_rgb)\n",
        "    self.avg_pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    self.final_block = nn.Sequential(\n",
        "        WSConv2d(in_channels+1, in_channels, kernel_size=3, stride=1, padding=1),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        WSConv2d(in_channels, in_channels, kernel_size=4, padding=0, stride=1),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        WSConv2d(in_channels, 1, kernel_size=1, padding=0, stride=1)\n",
        "    )\n",
        "\n",
        "  def _fade_in(self, alpha, downscaled, out):\n",
        "    return alpha*out + (1-alpha)*downscaled\n",
        "  \n",
        "  def minibatch_std(self, x):\n",
        "    batch_statistics = torch.std(x, dim=0).mean().repeat(x.shape[0], 1, x.shape[2], x.shape[3])\n",
        "    return torch.cat([x, batch_statistics], dim=1)\n",
        "\n",
        "  def forward(self, x, alpha, steps):\n",
        "    cur_step = len(self.prog_blocks) - steps\n",
        "    out = self.leaky(self.rgb_layers[cur_step](x))\n",
        "\n",
        "    if steps == 0:\n",
        "      out = self.minibatch_std(out)\n",
        "      return self.final_block(out).view(out.shape[0], -1)\n",
        "    \n",
        "    downscaled = self.leaky(self.rgb_layers[cur_step + 1](self.avg_pool(x)))\n",
        "    out = self.avg_pool(self.prog_blocks[cur_step](out))\n",
        "    out = self._fade_in(alpha, downscaled, out)\n",
        "\n",
        "    for step in range(cur_step+1, len(self.prog_blocks)):\n",
        "      out = self.prog_blocks[step](out)\n",
        "      out = self.avg_pool(out)\n",
        "\n",
        "    out = self.minibatch_std(out)\n",
        "    return self.final_block(out).view(out.shape[0], -1)"
      ],
      "metadata": {
        "id": "5iEgNdKk8qVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_penalty(critic, real, fake, alpha, train_step, device=\"cpu\"):\n",
        "    BATCH_SIZE, C, H, W = real.shape\n",
        "    beta = torch.rand((BATCH_SIZE, 1, 1, 1)).repeat(1, C, H, W).to(device)\n",
        "    interpolated_images = real * beta + fake.detach() * (1 - beta)\n",
        "    interpolated_images.requires_grad_(True)\n",
        "\n",
        "    # Calculate critic scores\n",
        "    mixed_scores = critic(interpolated_images, alpha, train_step)\n",
        "\n",
        "    # Take the gradient of the scores with respect to the images\n",
        "    gradient = torch.autograd.grad(\n",
        "        inputs=interpolated_images,\n",
        "        outputs=mixed_scores,\n",
        "        grad_outputs=torch.ones_like(mixed_scores),\n",
        "        create_graph=True,\n",
        "        retain_graph=True,\n",
        "    )[0]\n",
        "    gradient = gradient.view(gradient.shape[0], -1)\n",
        "    gradient_norm = gradient.norm(2, dim=1)\n",
        "    gradient_penalty = torch.mean((gradient_norm - 1) ** 2)\n",
        "    return gradient_penalty"
      ],
      "metadata": {
        "id": "nNlYNxk-LXrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download dataset\n",
        "import torchvision.datasets as datasets\n",
        "DATASET = datasets.StanfordCars('/data', download = True)"
      ],
      "metadata": {
        "id": "wKHEGi1Ou9LM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from os import cpu_count\n",
        "# Configuration file\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "START_TRAINING_IMG_SIZE = 4\n",
        "LR = 1e-3\n",
        "BATCH_SIZES = [32, 32, 32, 16, 16, 16, 16, 8, 4]\n",
        "IMG_CHANNELS = 3\n",
        "Z_DIM = 256\n",
        "IN_CHANNELS = 256\n",
        "CRITIC_ITERATIONS = 1\n",
        "LAMBDA_GP = 10\n",
        "PROGRESSIVE_EPOCHS = [30] * len(BATCH_SIZES)\n",
        "WORKERS = cpu_count()\n",
        "ALPHA_GP = 10"
      ],
      "metadata": {
        "id": "QSJsg8Ix53Sd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "#from tqdm import tqdm\n",
        "\n",
        "torch.backends.cudnn.benchmarks = True\n",
        "\n",
        "def get_loader(img_size):\n",
        "  transformations = transforms.Compose([\n",
        "                                  transforms.Resize((img_size, img_size)),\n",
        "                                  transforms.ToTensor(),\n",
        "                                  transforms.RandomHorizontalFlip(0.5),\n",
        "                                  transforms.Normalize([0.5 for _ in range(IMG_CHANNELS)], [0.5 for _ in range(IMG_CHANNELS)])\n",
        "  ])\n",
        "  batch_size = BATCH_SIZES[int(log2(img_size/4))]\n",
        "  dataset = datasets.StanfordCars(root=\"/data\", transform=transformations)\n",
        "  loader = DataLoader(dataset, batch_size, shuffle=True, pin_memory=True, num_workers=WORKERS)\n",
        "  return loader, dataset\n",
        "\n",
        "def train_loop(critic, generator, loader, dataset, step, alpha, opt_critic, opt_generator, scaler_generator, scaler_critic):\n",
        "  for batch_idx, (real, _) in enumerate(loader):\n",
        "    real = real.to(DEVICE)\n",
        "    cur_batch_size = real.shape[0]\n",
        "\n",
        "    noise = torch.randn(cur_batch_size, Z_DIM, 1, 1).to(DEVICE)\n",
        "\n",
        "    # Train the critic\n",
        "    with torch.cuda.amp.autocast():\n",
        "      fake = generator(noise, alpha, step)\n",
        "      scores_real = critic(real, alpha, step)\n",
        "      scores_fake = critic(fake.detach(), alpha, step)\n",
        "\n",
        "      gp = gradient_penalty(critic, real, fake, alpha, step, device=DEVICE)\n",
        "      loss_critic = (\n",
        "          -(torch.mean(scores_real) - torch.mean(scores_fake))\n",
        "          + LAMBDA_GP*gp\n",
        "          + (0.001 * torch.mean(scores_real**2))\n",
        "      )\n",
        "    \n",
        "    opt_critic.zero_grad()\n",
        "    scaler_critic.scale(loss_critic).backward()\n",
        "    scaler_critic.step(opt_critic)\n",
        "    scaler_critic.update()\n",
        "\n",
        "    # Train the generator\n",
        "    with torch.cuda.amp.autocast():\n",
        "      gen_fake = critic(fake, alpha, step)\n",
        "      loss_gen = -torch.mean(gen_fake)\n",
        "    \n",
        "    opt_generator.zero_grad()\n",
        "    scaler_generator.scale(loss_gen).backward()\n",
        "    scaler_generator.step(opt_generator)\n",
        "    scaler_generator.update()\n",
        "\n",
        "    # Update the alpha\n",
        "    alpha += cur_batch_size / ((PROGRESSIVE_EPOCHS[step]*0.5)*len(dataset))\n",
        "    alpha = min(alpha, 1)\n",
        "\n",
        "    if batch_idx%500==0:\n",
        "      print(f\"GP: {gp.cpu().detach().numpy()}, loss: {loss_critic}\")\n",
        "    \n",
        "  return alpha"
      ],
      "metadata": {
        "id": "fu8q8LxXby5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = Generator(Z_DIM, IN_CHANNELS, IMG_CHANNELS).to(DEVICE)\n",
        "critic = Discriminator(Z_DIM, IN_CHANNELS, IMG_CHANNELS).to(DEVICE)\n",
        "\n",
        "scaler_generator = torch.cuda.amp.GradScaler()\n",
        "scaler_critic = torch.cuda.amp.GradScaler()\n",
        "\n",
        "generator.train()\n",
        "critic.train()"
      ],
      "metadata": {
        "id": "dTqqCorT4f5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_generator = optim.Adam(generator.parameters(), lr=LR, betas=(0, 0.99))\n",
        "optimizer_critic = optim.Adam(critic.parameters(), lr=LR, betas=(0, 0.99))"
      ],
      "metadata": {
        "id": "q3PbMJGvEBc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(5):\n",
        "  step=int(log2(START_TRAINING_IMG_SIZE/4))\n",
        "  for num_epochs in PROGRESSIVE_EPOCHS[step:]:\n",
        "    alpha = 1e-5\n",
        "    loader, dataset = get_loader(4 * 2**step)\n",
        "    print(f\"Current image size: {4 * 2 ** step}\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "      print(f\"Epoch: [{epoch+1}/{num_epochs}]\")\n",
        "      alpha = train_loop(critic, generator, loader, dataset, step, alpha, optimizer_critic, optimizer_generator, scaler_generator, scaler_critic)\n",
        "    step += 1\n",
        "\n",
        "torch.save(generator.state_dict(), 'generator_weights.pth')\n",
        "torch.save(generator, 'generator.pth')"
      ],
      "metadata": {
        "id": "MvqAKF-L-qBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check how discriminator works\n",
        "with torch.no_grad():\n",
        "  example = generator(torch.randn(4, Z_DIM, 1, 1).to(DEVICE), 0.5, 5)\n",
        "  scores = critic(example, 1, 5)\n",
        "  print(scores, \"\\n\", scores.shape)"
      ],
      "metadata": {
        "id": "2ooVi52LIfZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fixed_noise = torch.randn(20, Z_DIM, 1, 1).to(DEVICE)"
      ],
      "metadata": {
        "id": "bvXJBGZTAnuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate some examples\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "with torch.no_grad():\n",
        "  generator.eval()\n",
        "  example = generator(fixed_noise, 1, 8) * 0.5 + 0.5\n",
        "  print(example.shape)\n",
        "  grid = torchvision.utils.make_grid(example.cpu().detach(), nrow=5)\n",
        "  plt.figure(figsize=(20, 16))\n",
        "  plt.imshow(grid.permute(1, 2, 0))\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "generator.train()\n",
        "print()"
      ],
      "metadata": {
        "id": "Ps3C0vX4-TYD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}